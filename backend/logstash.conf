# Logstash Configuration for Kaleidoscope Multi-Service Logging
# Version 3.0: Final syntax review and simplification

# ==============================================================================
# INPUTS: Defines how Logstash receives log data.
# ==============================================================================
input {
  # For logs from the Java Spring Boot application
  tcp {
    port  => 5000
    codec => "json_lines"
    tags  => ["java-backend"]
  }

  # For logs from a future Python ML service
  tcp {
    port  => 5001
    codec => "json_lines"
    tags  => ["python-ml"]
  }

  # For services that can push logs via HTTP
  http {
    port => 5002
    tags => ["http-source"]
  }

  # For logs from Filebeat or other Elastic Beats
  beats {
    port => 5044
    tags => ["beats-source"]
  }
}

# ==============================================================================
# FILTER: The main processing section. Logs are parsed and enriched here.
# ==============================================================================
filter {
  # --- Step 1: Basic Structuring ---
  # Set a metadata field for the index name. Defaults to 'unknown'.
  mutate {
    add_field => { "[@metadata][index_prefix]" => "kaleidoscope-unknown" }
  }
  if [service] {
    mutate {
      # Overwrite with the service name if it exists in the log event.
      add_field => { "[@metadata][index_prefix]" => "%{service}" }
    }
  }

  # --- Step 2: Promote Key Fields from MDC ---
  # Move important fields from the 'mdc' object to the top level for easier access.
  if [mdc] {
    mutate {
      add_field => {
        "correlation_id"      => "%{[mdc][correlationId]}"
        "request_method"      => "%{[mdc][requestMethod]}"
        "request_uri"         => "%{[mdc][requestUri]}"
        "response_status"     => "%{[mdc][responseStatus]}"
        "response_time_ms"    => "%{[mdc][responseTimeMs]}"
        "client_ip"           => "%{[mdc][clientIp]}"
        "user_agent_original" => "%{[mdc][userAgent]}"
      }
    }
  }

  # --- Step 3: Data Type Conversion ---
  # Ensure numeric fields are stored as numbers, not strings.
  mutate {
    convert => {
      "response_status"  => "integer"
      "response_time_ms" => "integer"
    }
  }

  # --- Step 4: External Data Enrichment ---
  # Add geographic information based on the client's IP address.
  if [client_ip] and [client_ip] !~ /^(127\.|10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Parse the user agent string to identify browser, OS, and device.
  if [user_agent_original] {
    useragent {
      source => "user_agent_original"
      target => "user_agent"
    }
  }

  # --- Step 5: Categorization based on Content ---
  # Add a category based on the API endpoint that was called.
  if [request_uri] {
    if "/api/auth" in [request_uri] {
      mutate { add_field => { "api_category" => "authentication" } }
    } else if "/api/users" in [request_uri] {
      mutate { add_field => { "api_category" => "user_management" } }
    } else if "/api/posts" in [request_uri] {
      mutate { add_field => { "api_category" => "content_management" } }
    } else if "/actuator" in [request_uri] {
      mutate { add_field => { "api_category" => "monitoring" } }
    } else {
      mutate { add_field => { "api_category" => "other" } }
    }
  }

  # Categorize performance based on response time.
  if [response_time_ms] {
    if [response_time_ms] >= 1000 {
      mutate { add_field => { "performance_category" => "very_slow" } }
    } else if [response_time_ms] >= 500 {
      mutate { add_field => { "performance_category" => "slow" } }
    } else if [response_time_ms] >= 100 {
      mutate { add_field => { "performance_category" => "normal" } }
    } else {
      mutate { add_field => { "performance_category" => "fast" } }
    }
  }

  # Categorize the result based on the HTTP status code.
  if [response_status] {
    if [response_status] >= 500 {
      mutate { add_field => { "status_category" => "server_error" } }
    } else if [response_status] >= 400 {
      mutate { add_field => { "status_category" => "client_error" } }
    } else if [response_status] >= 300 {
      mutate { add_field => { "status_category" => "redirect" } }
    } else if [response_status] >= 200 {
      mutate { add_field => { "status_category" => "success" } }
    }
  }

  # --- Step 6: Timestamp and Security ---
  # CRITICAL FIX: Use the correct ISO8601 standard for timestamps.
  date {
    match  => ["@timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Add extra time-based fields for easier filtering in Kibana.
  ruby {
    code => "
      event.set('hour_of_day', event.get('@timestamp').time.hour)
      event.set('day_of_week', event.get('@timestamp').time.strftime('%A'))
    "
  }

  # Tag potential security attacks based on URI patterns.
  if [request_uri] and ([request_uri] =~ /\.\./ or [request_uri] =~ /<script/ or [request_uri] =~ /javascript:/ or [request_uri] =~ /eval\(/ or [request_uri] =~ /(?i)union.*select/) {
    mutate {
      add_tag   => ["security_incident"]
      add_field => { "security_alert" => "potential_attack_detected" }
    }
  }

  # Identify and tag traffic from bots.
  if [user_agent_original] {
    if [user_agent_original] =~ /(?i)bot|crawler|spider|scraper/ {
      mutate {
        add_tag   => ["bot_traffic"]
        add_field => { "request_type" => "bot" }
      }
    } else {
      mutate {
        add_field => { "request_type" => "human" }
      }
    }
  }

  # --- Step 7: Final Cleanup ---
  # Remove temporary fields to keep the final output clean.
  mutate {
    remove_field => ["mdc", "user_agent_original"]
  }
}

# ==============================================================================
# OUTPUTS: Defines where Logstash sends the processed data.
# ==============================================================================
output {
  # Send to Elasticsearch for storage and analysis.
  elasticsearch {
    hosts           => ["http://elasticsearch:9200"]
    index           => "%{[@metadata][index_prefix]}-%{+yyyy.MM.dd}"
    manage_template => true
  }

  # Also print to the console for real-time debugging.
  stdout {
    codec => "rubydebug"
  }
}